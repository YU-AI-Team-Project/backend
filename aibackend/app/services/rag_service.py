import openai
import os
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import func, text
from dotenv import load_dotenv
from aibackend.app.news_vector import NewsVector
from aibackend.app.news_vector_db import get_news_db

load_dotenv()

class RAGService:
    def __init__(self):
        self.openai_client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.embedding_model = "text-embedding-ada-002"
        self.chat_model = "gpt-4o"
    
    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            response = self.openai_client.embeddings.create(
                input=[text],
                model=self.embedding_model
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def similarity_search(
        self, 
        query: str, 
        db: Session, 
        top_k: int = 5,
        similarity_threshold: float = 0.7
    ) -> List[Dict[str, Any]]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ì°¾ê¸°"""
        try:
            # ì¿¼ë¦¬ ì„ë² ë”©
            query_embedding = self.get_embedding(query)
            if not query_embedding:
                return []
            
            # pgvectorì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰
            # 1 - (embedding <=> query_embedding)ìœ¼ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
            query_text = text("""
                SELECT id, title, content, published_at,
                       1 - (embedding <=> :query_embedding) as similarity
                FROM news_vectors
                WHERE 1 - (embedding <=> :query_embedding) > :threshold
                ORDER BY embedding <=> :query_embedding
                LIMIT :limit
            """)
            
            result = db.execute(
                query_text,
                {
                    "query_embedding": query_embedding,
                    "threshold": similarity_threshold,
                    "limit": top_k
                }
            )
            
            similar_docs = []
            for row in result:
                similar_docs.append({
                    "id": str(row.id),
                    "title": row.title,
                    "content": row.content,
                    "published_at": row.published_at.isoformat() if row.published_at else None,
                    "similarity": float(row.similarity)
                })
            
            return similar_docs
            
        except Exception as e:
            print(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def generate_response(
        self, 
        query: str, 
        context_docs: List[Dict[str, Any]],
        system_prompt: Optional[str] = None
    ) -> str:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
        try:
            # ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            context_text = "\n\n".join([
                f"ì œëª©: {doc['title']}\në‚´ìš©: {doc['content']}\në°œí–‰ì¼: {doc['published_at']}"
                for doc in context_docs
            ])
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
            if not system_prompt:
                system_prompt = """ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ì¶œì‹ ì˜ ì „ë¬¸ ì£¼ì‹ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì œê³µëœ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ê¸°ì—…ì˜ íˆ¬ì ì í•©ì„± ì—¬ë¶€ë¥¼ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”.

ğŸ¯ ë‹¹ì‹ ì˜ ë¶„ì„ ì‘ì—…:
1. ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ ë° ê¸/ë¶€ì • íŒë‹¨
2. íˆ¬ì ê´€ì ì—ì„œì˜ ì˜ë¯¸ í•´ì„
3. íˆ¬ì ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ ì •ë³´ ì œê³µ

ğŸ§¾ ì¶œë ¥ í˜•ì‹:

[ë‰´ìŠ¤ ë¶„ì„]:
- í•µì‹¬ ë‚´ìš© ì •ë¦¬:
- íˆ¬ì ê´€ì  íŒë‹¨: âœ… ê¸ì •ì  / âš ï¸ ì£¼ì˜ / âŒ ë¶€ì •ì 
- íŒë‹¨ ê·¼ê±°:

[íˆ¬ì ê´€ì ]:
- ë‹¨ê¸° ì˜í–¥:
- ì¤‘ì¥ê¸° ì „ë§:
- ì£¼ìš” ë¦¬ìŠ¤í¬:

[ì¢…í•© ì˜ê²¬]:
- íˆ¬ì ë°©í–¥ì„±:
- ì£¼ì˜ì‚¬í•­:

âš ï¸ ì‘ì„± ì¡°ê±´:
- ë¶„ì„ì€ ì „ë¬¸ê°€ ì‹œì ì—ì„œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±
- ë‰´ìŠ¤ ë‚´ìš©ì„ ì¸ìš©í•´ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
- íˆ¬ì ìœ„í—˜ì„±ì„ ë°˜ë“œì‹œ ì–¸ê¸‰
- ê°ê´€ì ì´ê³  ê· í˜•ì¡íŒ ì‹œê° ìœ ì§€
- êµ¬ì²´ì ì¸ ë§¤ìˆ˜/ë§¤ë„ ì¡°ì–¸ë³´ë‹¤ëŠ” ì •ë³´ ì œê³µì— ì¤‘ì """
            
            # GPTì—ê²Œ ì§ˆë¬¸ê³¼ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"""
ë‹¤ìŒì€ ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì…ë‹ˆë‹¤:

{context_text}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ìœ„ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
"""}
            ]
            
            response = self.openai_client.chat.completions.create(
                model=self.chat_model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def generate_stock_analysis(
        self,
        stock_code: str,
        news_query: str,
        financial_data: Optional[str] = None,
        db: Session = None
    ) -> Dict[str, Any]:
        """ì£¼ì‹ ë¶„ì„ìš© íŠ¹í™” RAG (ë‰´ìŠ¤ + ì¬ë¬´ ë°ì´í„°)"""
        try:
            # 1. í•´ë‹¹ ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰
            search_query = f"{stock_code} {news_query}"
            similar_docs = self.similarity_search(
                query=search_query,
                db=db,
                top_k=5,
                similarity_threshold=0.6
            )
            
            if not similar_docs:
                return {
                    "stock_code": stock_code,
                    "query": news_query,
                    "response": f"{stock_code} ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "success": False
                }
            
            # 2. ì£¼ì‹ ë¶„ì„ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            analysis_prompt = """ë‹¹ì‹ ì€ ì›”ìŠ¤íŠ¸ë¦¬íŠ¸ ì¶œì‹ ì˜ ì „ë¬¸ ì£¼ì‹ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ë‰´ìŠ¤ ê¸°ì‚¬ì™€ ì¬ë¬´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í•´ë‹¹ ê¸°ì—…ì˜ íˆ¬ì ì í•©ì„± ì—¬ë¶€ë¥¼ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”.

ğŸ“Œ ì£¼ì–´ì§€ëŠ” ë°ì´í„°:
- ë‰´ìŠ¤ ê¸°ì‚¬ (ì œëª© + ë³¸ë¬¸)
- ì¬ë¬´ ì •ë³´ (ì œê³µëœ ê²½ìš°)

ğŸ¯ ë‹¹ì‹ ì˜ ë¶„ì„ ì‘ì—…:
1. ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„ ë° ê¸/ë¶€ì • íŒë‹¨
2. ì¬ë¬´ ì§€í‘œ ë¶„ì„ (ì œê³µëœ ê²½ìš°)
3. ìµœì¢… íˆ¬ì ì˜ê²¬ ì œì‹œ

ğŸ§¾ ì¶œë ¥ í˜•ì‹:

[ë‰´ìŠ¤ ë¶„ì„]:
- í•µì‹¬ ë‚´ìš© ì •ë¦¬:
- íˆ¬ì ê´€ì  íŒë‹¨: âœ… ê¸ì •ì  / âš ï¸ ì£¼ì˜ / âŒ ë¶€ì •ì 
- íŒë‹¨ ê·¼ê±°:

[ì¬ë¬´ ë¶„ì„] (ì¬ë¬´ ë°ì´í„°ê°€ ì œê³µëœ ê²½ìš°):
- ìˆ˜ìµì„± ë¶„ì„:
- ì¬ë¬´ê±´ì „ì„±:
- ì‹œì¥ì§€í‘œ í•´ì„:

[ì¢…í•© íŒë‹¨]:
- íˆ¬ì ë°©í–¥ì„±: ê´€ì‹¬ / ê´€ë§ / ì£¼ì˜
- ì£¼ìš” ê·¼ê±°:
- ë¦¬ìŠ¤í¬ ìš”ì¸:

âš ï¸ ì‘ì„± ì¡°ê±´:
- ë¶„ì„ì€ ì „ë¬¸ê°€ ì‹œì ì—ì„œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±
- ìˆ˜ì¹˜ë¥¼ ì¸ìš©í•´ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª… (ì¬ë¬´ ë°ì´í„° ìˆëŠ” ê²½ìš°)
- íˆ¬ì ìœ„í—˜ì„±ì„ ë°˜ë“œì‹œ ì–¸ê¸‰
- êµ¬ì²´ì ì¸ ë§¤ìˆ˜/ë§¤ë„ ì¡°ì–¸ë³´ë‹¤ëŠ” ì •ë³´ ì œê³µì— ì¤‘ì """
            
            # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_text = "\n\n".join([
                f"ì œëª©: {doc['title']}\në‚´ìš©: {doc['content']}\në°œí–‰ì¼: {doc['published_at']}"
                for doc in similar_docs
            ])
            
            # 4. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_content = f"""
[ë¶„ì„ ëŒ€ìƒ ì¢…ëª©]: {stock_code}

[ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤]:
{context_text}
"""
            
            # ì¬ë¬´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if financial_data:
                user_content += f"\n[ì¬ë¬´ ì •ë³´]:\n{financial_data}\n"
            
            user_content += f"\n[ë¶„ì„ ìš”ì²­]: {news_query}"
            
            # 5. GPT ë¶„ì„ ì‹¤í–‰
            messages = [
                {"role": "system", "content": analysis_prompt},
                {"role": "user", "content": user_content}
            ]
            
            response = self.openai_client.chat.completions.create(
                model=self.chat_model,
                messages=messages,
                temperature=0.7,
                max_tokens=1500
            )
            
            return {
                "stock_code": stock_code,
                "query": news_query,
                "response": response.choices[0].message.content,
                "sources": similar_docs,
                "has_financial_data": bool(financial_data),
                "success": True
            }
            
        except Exception as e:
            print(f"ì£¼ì‹ ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "stock_code": stock_code,
                "query": news_query,
                "response": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "sources": [],
                "success": False
            }

    def rag_query(
        self, 
        query: str, 
        db: Session,
        top_k: int = 5,
        similarity_threshold: float = 0.7,
        system_prompt: Optional[str] = None
    ) -> Dict[str, Any]:
        """RAG íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰"""
        try:
            # 1. ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
            similar_docs = self.similarity_search(
                query=query,
                db=db,
                top_k=top_k,
                similarity_threshold=similarity_threshold
            )
            
            if not similar_docs:
                return {
                    "query": query,
                    "response": "ê´€ë ¨ëœ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.",
                    "sources": [],
                    "success": False
                }
            
            # 2. ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
            response = self.generate_response(
                query=query,
                context_docs=similar_docs,
                system_prompt=system_prompt
            )
            
            return {
                "query": query,
                "response": response,
                "sources": similar_docs,
                "success": True
            }
            
        except Exception as e:
            print(f"RAG ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "query": query,
                "response": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "sources": [],
                "success": False
            }

# ì „ì—­ RAG ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
rag_service = RAGService() 