import os
import sys
import time
import random
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs
from sqlalchemy import text
from dotenv import load_dotenv

# ê²½ë¡œ ì„¤ì •ì„ í†µí•´ aibackend íŒ¨í‚¤ì§€ë¥¼ import í•  ìˆ˜ ìˆë„ë¡ í•¨
backend_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
sys.path.append(backend_path)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼)
dotenv_path = os.path.join(backend_path, '.env')
load_dotenv(dotenv_path)

# aibackendì—ì„œ í•„ìš”í•œ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°
from aibackend.app.news_vector_db import NewsSessionLocal

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ íŒŒë¼ë¯¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def search_naver_news_url(title: str, content: str = "") -> str:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ì œëª©ìœ¼ë¡œ ê¸°ì‚¬ URL ê²€ìƒ‰"""
    try:
        # ê²€ìƒ‰ì–´ ì¤€ë¹„ (ì œëª©ì˜ ì²˜ìŒ 50ìë§Œ ì‚¬ìš©)
        search_query = title[:50].strip()
        if not search_query:
            return None
        
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ URL
        search_url = f"https://search.naver.com/search.naver?where=news&query={search_query}"
        
        time.sleep(random.uniform(1.0, 2.0))  # ìš”ì²­ ê°„ê²©
        response = requests.get(search_url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë‰´ìŠ¤ ë§í¬ ì°¾ê¸°
        news_items = soup.select(".news_area")
        
        for item in news_items[:3]:  # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ í™•ì¸
            # ì œëª© ìš”ì†Œ ì°¾ê¸°
            title_elem = item.select_one(".news_tit")
            if not title_elem:
                continue
                
            # ì œëª© í…ìŠ¤íŠ¸ ë¹„êµ
            found_title = title_elem.get_text(strip=True)
            
            # ì œëª© ìœ ì‚¬ë„ ì²´í¬ (ê°„ë‹¨í•œ í¬í•¨ ê´€ê³„)
            title_words = set(title.replace(" ", "").lower())
            found_words = set(found_title.replace(" ", "").lower())
            
            # 70% ì´ìƒ ê²¹ì¹˜ë©´ ê°™ì€ ê¸°ì‚¬ë¡œ íŒë‹¨
            if len(title_words & found_words) / len(title_words) > 0.7:
                url = title_elem.get("href")
                if url:
                    print(f"âœ… URL ì°¾ìŒ: {title[:30]}... -> {url}")
                    return url
        
        print(f"âš ï¸ URL ëª»ì°¾ìŒ: {title[:30]}...")
        return None
        
    except Exception as e:
        print(f"âŒ URL ê²€ìƒ‰ ì‹¤íŒ¨ ({title[:30]}...): {e}")
        return None

def update_news_with_urls():
    """ê¸°ì¡´ ë‰´ìŠ¤ ë°ì´í„°ì— URL ì¶”ê°€"""
    session = NewsSessionLocal()
    
    try:
        # URLì´ ì—†ëŠ” ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ
        print("ğŸ” URLì´ ì—†ëŠ” ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì¤‘...")
        
        query = text("""
            SELECT id, title, content 
            FROM news_vectors 
            WHERE url IS NULL OR url = ''
            ORDER BY published_at DESC
            LIMIT 100
        """)
        
        result = session.execute(query)
        news_list = result.fetchall()
        
        print(f"ğŸ“Š ì²˜ë¦¬í•  ë‰´ìŠ¤ ìˆ˜: {len(news_list)}ê°œ")
        
        if not news_list:
            print("âœ… ëª¨ë“  ë‰´ìŠ¤ì— URLì´ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤!")
            return
        
        updated_count = 0
        failed_count = 0
        
        for i, news in enumerate(news_list, 1):
            print(f"\nğŸ”„ [{i}/{len(news_list)}] ì²˜ë¦¬ ì¤‘: {news.title[:50]}...")
            
            # URL ê²€ìƒ‰
            found_url = search_naver_news_url(news.title, news.content)
            
            if found_url:
                # URL ì—…ë°ì´íŠ¸
                try:
                    update_query = text("""
                        UPDATE news_vectors 
                        SET url = :url 
                        WHERE id = :id
                    """)
                    
                    session.execute(update_query, {
                        "url": found_url,
                        "id": news.id
                    })
                    session.commit()
                    
                    updated_count += 1
                    print(f"âœ… URL ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                    
                except Exception as e:
                    print(f"âŒ DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                    session.rollback()
                    failed_count += 1
            else:
                failed_count += 1
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if i % 10 == 0:
                print(f"ğŸ“ˆ ì§„í–‰ë¥ : {i}/{len(news_list)} ({i/len(news_list)*100:.1f}%)")
                print(f"   ì—…ë°ì´íŠ¸: {updated_count}ê°œ, ì‹¤íŒ¨: {failed_count}ê°œ")
        
        print(f"\nğŸ‰ URL ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µ: {updated_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
        print(f"ğŸ“Š ì„±ê³µë¥ : {updated_count/(updated_count+failed_count)*100:.1f}%")
        
    except Exception as e:
        print(f"âŒ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        session.rollback()
    finally:
        session.close()

def update_news_with_manual_search():
    """ìˆ˜ë™ìœ¼ë¡œ URL íŒ¨í„´ì„ ë§Œë“¤ì–´ ì—…ë°ì´íŠ¸ (ë” ì •í™•í•œ ë°©ë²•)"""
    session = NewsSessionLocal()
    
    try:
        print("ğŸ” ì œëª©ì—ì„œ ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ì¶œí•˜ì—¬ URL ìƒì„± ì‹œë„...")
        
        # ì œëª©ì—ì„œ ì–¸ë¡ ì‚¬ ì •ë³´ê°€ ìˆëŠ” ë‰´ìŠ¤ ì¡°íšŒ
        query = text("""
            SELECT id, title, content, published_at
            FROM news_vectors 
            WHERE url IS NULL OR url = ''
            ORDER BY published_at DESC
            LIMIT 50
        """)
        
        result = session.execute(query)
        news_list = result.fetchall()
        
        print(f"ğŸ“Š ì²˜ë¦¬í•  ë‰´ìŠ¤ ìˆ˜: {len(news_list)}ê°œ")
        
        updated_count = 0
        
        for i, news in enumerate(news_list, 1):
            print(f"\nğŸ”„ [{i}/{len(news_list)}] {news.title[:50]}...")
            
            # ê°„ë‹¨í•œ URL ìƒì„± ì‹œë„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
            # ì—¬ê¸°ì„œëŠ” ë‰´ìŠ¤ ì œëª©ê³¼ ë‚´ìš©ìœ¼ë¡œ ê²€ìƒ‰í•˜ëŠ” ë°©ì‹ ì‚¬ìš©
            found_url = search_naver_news_url(news.title)
            
            if found_url:
                try:
                    update_query = text("""
                        UPDATE news_vectors 
                        SET url = :url 
                        WHERE id = :id
                    """)
                    
                    session.execute(update_query, {
                        "url": found_url,
                        "id": news.id
                    })
                    session.commit()
                    
                    updated_count += 1
                    print(f"âœ… URL ì—…ë°ì´íŠ¸ ì™„ë£Œ: {found_url}")
                    
                except Exception as e:
                    print(f"âŒ DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                    session.rollback()
        
        print(f"\nğŸ‰ URL ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ì—…ë°ì´íŠ¸: {updated_count}ê°œ)")
        
    except Exception as e:
        print(f"âŒ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        session.rollback()
    finally:
        session.close()

def check_current_status():
    """í˜„ì¬ DB ìƒíƒœ í™•ì¸"""
    session = NewsSessionLocal()
    
    try:
        # ì „ì²´ ë‰´ìŠ¤ ìˆ˜
        total_query = text("SELECT COUNT(*) FROM news_vectors")
        total_count = session.execute(total_query).scalar()
        
        # URLì´ ìˆëŠ” ë‰´ìŠ¤ ìˆ˜
        with_url_query = text("SELECT COUNT(*) FROM news_vectors WHERE url IS NOT NULL AND url != ''")
        with_url_count = session.execute(with_url_query).scalar()
        
        # URLì´ ì—†ëŠ” ë‰´ìŠ¤ ìˆ˜
        without_url_count = total_count - with_url_count
        
        print(f"ğŸ“Š í˜„ì¬ DB ìƒíƒœ:")
        print(f"   ì „ì²´ ë‰´ìŠ¤: {total_count}ê°œ")
        print(f"   URL ìˆìŒ: {with_url_count}ê°œ ({with_url_count/total_count*100:.1f}%)")
        print(f"   URL ì—†ìŒ: {without_url_count}ê°œ ({without_url_count/total_count*100:.1f}%)")
        
        return without_url_count > 0
        
    except Exception as e:
        print(f"âŒ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False
    finally:
        session.close()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ê¸°ì¡´ ë‰´ìŠ¤ ë°ì´í„°ì— URL ì¶”ê°€ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
    
    # í˜„ì¬ ìƒíƒœ í™•ì¸
    needs_update = check_current_status()
    
    if not needs_update:
        print("âœ… ëª¨ë“  ë‰´ìŠ¤ì— URLì´ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤!")
        return
    
    print("\n" + "="*50)
    print("URL ì—…ë°ì´íŠ¸ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ìë™ ê²€ìƒ‰ (ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‚¬ìš©)")
    print("2. ìƒíƒœ í™•ì¸ë§Œ")
    print("="*50)
    
    try:
        choice = input("ì„ íƒ (1 ë˜ëŠ” 2): ").strip()
        
        if choice == "1":
            print("\nğŸ” ìë™ URL ê²€ìƒ‰ ì‹œì‘...")
            update_news_with_urls()
        elif choice == "2":
            print("\nğŸ“Š ìƒíƒœ í™•ì¸ ì™„ë£Œ")
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main() 